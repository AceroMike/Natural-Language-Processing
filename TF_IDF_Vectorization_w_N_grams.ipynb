{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF-IDF Vectorization w/ N-grams.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNPZOJWuMJ/rmHcRaCW0w1Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AceroMike/Natural-Language-Processing/blob/main/TF_IDF_Vectorization_w_N_grams.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDevA6MgrXZF"
      },
      "source": [
        "# Imports\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import spacy\r\n",
        "import re\r\n",
        "\r\n",
        "import nltk\r\n",
        "from nltk.corpus import gutenberg\r\n",
        "\r\n",
        "import sklearn\r\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "import warnings\r\n",
        "warnings.filterwarnings(\"ignore\")\r\n",
        "\r\n",
        "nltk.download('gutenberg')\r\n",
        "!python -m spacy download en"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrU6H-OxqsJI"
      },
      "source": [
        "Converting words or sentences into numeric vectors is fundamental when working with text data. There are many ways to convert text to numerical data and in this Notebook I will discuss **TF-IDF** vectorization. And provide a few examples. Let's start simple with some random sentences. Suppose we have the following sentences."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvJ31zmebFzr"
      },
      "source": [
        "1. \"The Lumberjack Song is the funniest Monty Python bit; I can't think of it without laughing.\"\r\n",
        "2. \"I would rather put strawberries on my ice cream for dessert; they have the best taste.\"\r\n",
        "3. \"The taste of caramel is a fantastic accompaniment to tasty mint ice cream.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkkVviBtrzrp"
      },
      "source": [
        "Before we can do anything with these sentences we first want to put it in a format that will allow us to preprocess the data and remove stopwords, punctuation, and lemmatize the resulting tokens. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "3zzHrgbQg-7e",
        "outputId": "01945672-e095-404b-910c-866bb79e5b7b"
      },
      "source": [
        "# Creating the text string\r\n",
        "sentences = \"The Lumberjack Song is the funniest Monty Python bit; I can't think of it without laughing. I would rather put strawberries on my ice cream for dessert; they have the best taste. The taste of caramel is a fantastic accompaniment to tasty mint ice cream.\"\r\n",
        "sentences"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"The Lumberjack Song is the funniest Monty Python bit; I can't think of it without laughing. I would rather put strawberries on my ice cream for dessert; they have the best taste. The taste of caramel is a fantastic accompaniment to tasty mint ice cream.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ccLwRbus176"
      },
      "source": [
        "Now we can use spaCy to parse the text and tokenize it for use. This is very easy to do but can take a while with larger data sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeXR8KpFsTvz",
        "outputId": "2aea5dd4-3cf5-4cad-f2a2-939330358764"
      },
      "source": [
        "nlp = spacy.load('en')\r\n",
        "\r\n",
        "sentences = nlp(sentences)\r\n",
        "sentences"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "The Lumberjack Song is the funniest Monty Python bit; I can't think of it without laughing. I would rather put strawberries on my ice cream for dessert; they have the best taste. The taste of caramel is a fantastic accompaniment to tasty mint ice cream."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3gwKguGtbEz"
      },
      "source": [
        "Although I have called the now parsed and tokenized data sentences. I don't actually have sentences, Yet. Now let's group the text by sentences and create a DataFrame. Then, we will be able to apply TF-IDF Vectorization on the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekakZ482tHw5",
        "outputId": "0b1a5579-2319-4ca0-ba08-19c6bbfb7204"
      },
      "source": [
        "# Group into sentences\r\n",
        "sentences = [[sent] for sent in sentences.sents]\r\n",
        "sentences"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[The Lumberjack Song is the funniest Monty Python bit; I can't think of it without laughing.],\n",
              " [I would rather put strawberries on my ice cream for dessert; they have the best taste.],\n",
              " [The taste of caramel is a fantastic accompaniment to tasty mint ice cream.]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "V99kanzytwW7",
        "outputId": "b534731c-c481-4172-8a2f-f09ff764749f"
      },
      "source": [
        "# Creating a DataFrame\r\n",
        "sentences = pd.DataFrame(sentences, columns = ['text'])\r\n",
        "sentences.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(The, Lumberjack, Song, is, the, funniest, Mon...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(I, would, rather, put, strawberries, on, my, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(The, taste, of, caramel, is, a, fantastic, ac...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0  (The, Lumberjack, Song, is, the, funniest, Mon...\n",
              "1  (I, would, rather, put, strawberries, on, my, ...\n",
              "2  (The, taste, of, caramel, is, a, fantastic, ac..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oG_GRbpht9_j"
      },
      "source": [
        "As we can see now, each sentence is separated by it's corresponding tokens. Now we want to remove punctuation, stopwords, and lemmatizing our tokens. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "LuCZcWwTuMJM",
        "outputId": "48a48462-a0e6-4155-de76-ac3d65d2474c"
      },
      "source": [
        "for i, sentence in enumerate(sentences[\"text\"]):\r\n",
        "    sentences.loc[i, \"text\"] = \" \".join(\r\n",
        "        [token.lemma_ for token in sentence if not token.is_punct and not token.is_stop])\r\n",
        "    \r\n",
        "sentences"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Lumberjack Song funniest Monty Python bit thin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>strawberry ice cream dessert good taste</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>taste caramel fantastic accompaniment tasty mi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0  Lumberjack Song funniest Monty Python bit thin...\n",
              "1            strawberry ice cream dessert good taste\n",
              "2  taste caramel fantastic accompaniment tasty mi..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f53s0D-fu-tQ"
      },
      "source": [
        "Now we can apply TF-IDF!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "7sim1KO7uPmB",
        "outputId": "bc0d4dee-8bd6-406f-b71b-26c3f0eab307"
      },
      "source": [
        "vectorizer = TfidfVectorizer(min_df=2, use_idf=True, norm=u'l2', smooth_idf=True)\r\n",
        "\r\n",
        "# Applying the vectorizer\r\n",
        "X = vectorizer.fit_transform(sentences['text'])\r\n",
        "\r\n",
        "tfidf_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\r\n",
        "sentences = pd.concat([tfidf_df, sentences[[\"text\"]]], axis=1)\r\n",
        "\r\n",
        "# Keep in mind that log base 2 of 1 is 0,\r\n",
        "# so a TF-IDF score of 0 indicates that the word was present once in that sentence.\r\n",
        "sentences.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cream</th>\n",
              "      <th>ice</th>\n",
              "      <th>taste</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>Lumberjack Song funniest Monty Python bit thin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.57735</td>\n",
              "      <td>0.57735</td>\n",
              "      <td>0.57735</td>\n",
              "      <td>strawberry ice cream dessert good taste</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.57735</td>\n",
              "      <td>0.57735</td>\n",
              "      <td>0.57735</td>\n",
              "      <td>taste caramel fantastic accompaniment tasty mi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     cream      ice    taste                                               text\n",
              "0  0.00000  0.00000  0.00000  Lumberjack Song funniest Monty Python bit thin...\n",
              "1  0.57735  0.57735  0.57735            strawberry ice cream dessert good taste\n",
              "2  0.57735  0.57735  0.57735  taste caramel fantastic accompaniment tasty mi..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBcj_yLKv15Q"
      },
      "source": [
        "We should not be surprised to see that the first sentence has 0 for all scores. The reason this occurs is that I only looked at words that appeared in at least 2 sentences. The last 2 sentences are about icecream while the first is about Monty Python being funny. \r\n",
        "\r\n",
        "Now that we have worked with some made up data, let's look at some actual data! This data comes from gutenberg. Which is data that can be downloaded by anyone. We will be generating TF-IDF vectors of Jane Austen's *Persuasion* and Lewis Carroll's *Alice's Adventures in Wonderland*.\r\n",
        "\r\n",
        "First, we must load and clean the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUqPCAujwwPL"
      },
      "source": [
        "# First defining a function that will help us clean the data\r\n",
        "def text_cleaner(text):\r\n",
        "    # Visual inspection identifies a form of punctuation that spaCy doesn't\r\n",
        "    # recognize: the double dash '--'. Better get rid of it now!\r\n",
        "    text = re.sub(r'--',' ',text)\r\n",
        "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\r\n",
        "    text = re.sub(r\"(\\b|\\s+\\-?|^\\-?)(\\d+|\\d*\\.\\d+)\\b\", \" \", text)\r\n",
        "    text = ' '.join(text.split())\r\n",
        "    return text"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkGtgvGjwd2r"
      },
      "source": [
        "persuasion = gutenberg.raw('austen-persuasion.txt')\r\n",
        "alice = gutenberg.raw('carroll-alice.txt')\r\n",
        "\r\n",
        "# The chapter indicator is idiosyncratic\r\n",
        "persuasion = re.sub(r'Chapter \\d+', '', persuasion)\r\n",
        "alice = re.sub(r'CHAPTER .*', '', alice)\r\n",
        "    \r\n",
        "alice = text_cleaner(alice)\r\n",
        "persuasion = text_cleaner(persuasion)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "DoZv0JOixB6j",
        "outputId": "e52411c6-6fe7-4a09-8836-282cd95c56cd"
      },
      "source": [
        "# First 500 words of Alice in Wonderland\r\n",
        "alice[0:500]"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do: once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it, 'and what is the use of a book,' thought Alice 'without pictures or conversation?' So she was considering in her own mind (as well as she could, for the hot day made her feel very sleepy and stupid), whether the pleasure of making a daisy-chain would be worth the trouble of gettin\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "H3bEGKoAxDo6",
        "outputId": "798db8bd-749e-41ee-fa21-c7941c101d1d"
      },
      "source": [
        "# Persuasion too\r\n",
        "persuasion[0:500]"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Sir Walter Elliot, of Kellynch Hall, in Somersetshire, was a man who, for his own amusement, never took up any book but the Baronetage; there he found occupation for an idle hour, and consolation in a distressed one; there his faculties were roused into admiration and respect, by contemplating the limited remnant of the earliest patents; there any unwelcome sensations, arising from domestic affairs changed naturally into pity and contempt as he turned over the almost endless creations of the las'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GrLLAscxGf9"
      },
      "source": [
        "As we can see, we have cleaned up the text but only to prepare it to further clean it! As before, we will want to create a DataFrame of each of the sentences in the book. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkU8PZ3-xFZh"
      },
      "source": [
        "nlp = spacy.load('en')\r\n",
        "\r\n",
        "# Bigger file, so may take a while!\r\n",
        "alice_doc = nlp(alice)\r\n",
        "persuasion_doc = nlp(persuasion)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoQew6cWxj4U",
        "outputId": "4b2e9eb7-5e94-4fee-f6fe-bcf1028e4ba0"
      },
      "source": [
        "alice_doc[0:500]"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do: once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it, 'and what is the use of a book,' thought Alice 'without pictures or conversation?' So she was considering in her own mind (as well as she could, for the hot day made her feel very sleepy and stupid), whether the pleasure of making a daisy-chain would be worth the trouble of getting up and picking the daisies, when suddenly a White Rabbit with pink eyes ran close by her. There was nothing so VERY remarkable in that; nor did Alice think it so VERY much out of the way to hear the Rabbit say to itself, 'Oh dear! Oh dear! I shall be late!' (when she thought it over afterwards, it occurred to her that she ought to have wondered at this, but at the time it all seemed quite natural); but when the Rabbit actually TOOK A WATCH OUT OF ITS WAISTCOAT-POCKET, and looked at it, and then hurried on, Alice started to her feet, for it flashed across her mind that she had never before seen a rabbit with either a waistcoat-pocket, or a watch to take out of it, and burning with curiosity, she ran across the field after it, and fortunately was just in time to see it pop down a large rabbit-hole under the hedge. In another moment down went Alice after it, never once considering how in the world she was to get out again. The rabbit-hole went straight on like a tunnel for some way, and then dipped suddenly down, so suddenly that Alice had not a moment to think about stopping herself before she found herself falling down a very deep well. Either the well was very deep, or she fell very slowly, for she had plenty of time as she went down to look about her and to wonder what was going to happen next. First, she tried to look down and make out what she was coming to, but it was too dark to see anything; then she looked at the sides of the well, and noticed that they were filled with cupboards and book-shelves; here and there she saw maps and pictures hung upon pegs. She took down a jar from one of the shelves as she passed; it was labelled 'ORANGE MARMALADE', but to her great disappointment it was empty: she did not like to drop the"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EfhB10sxlEV",
        "outputId": "5d36c5b9-399f-4e92-d0c6-fdd7197489bc"
      },
      "source": [
        "persuasion_doc[0:500]"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sir Walter Elliot, of Kellynch Hall, in Somersetshire, was a man who, for his own amusement, never took up any book but the Baronetage; there he found occupation for an idle hour, and consolation in a distressed one; there his faculties were roused into admiration and respect, by contemplating the limited remnant of the earliest patents; there any unwelcome sensations, arising from domestic affairs changed naturally into pity and contempt as he turned over the almost endless creations of the last century; and there, if every other leaf were powerless, he could read his own history with an interest which never failed. This was the page at which the favourite volume always opened: \"ELLIOT OF KELLYNCH HALL. \"Walter Elliot, born March , , married, July , , Elizabeth, daughter of James Stevenson, Esq. of South Park, in the county of Gloucester, by which lady (who died ) he has issue Elizabeth, born June , ; Anne, born August , ; a still-born son, November , ; Mary, born November , .\" Precisely such had the paragraph originally stood from the printer's hands; but Sir Walter had improved it by adding, for the information of himself and his family, these words, after the date of Mary's birth \"Married, December , , Charles, son and heir of Charles Musgrove, Esq. of Uppercross, in the county of Somerset,\" and by inserting most accurately the day of the month on which he had lost his wife. Then followed the history and rise of the ancient and respectable family, in the usual terms; how it had been first settled in Cheshire; how mentioned in Dugdale, serving the office of high sheriff, representing a borough in three successive parliaments, exertions of loyalty, and dignity of baronet, in the first year of Charles II, with all the Marys and Elizabeths they had married; forming altogether two handsome duodecimo pages, and concluding with the arms and motto: \"Principal seat, Kellynch Hall, in the county of Somerset,\" and Sir Walter's handwriting again in this finale: \"Heir presumptive, William Walter Elliot, Esq., great grandson of the second Sir Walter.\" Vanity was the beginning and the end of Sir Walter Elliot's character; vanity of person and of situation. He had been remarkably handsome in his youth; and, at fifty-four, was still a very fine man. Few women could think more of their personal appearance than he did, nor could the valet of any new made lord be more delighted with the place he held in society"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHOcONgLxnz4"
      },
      "source": [
        "Now it should start to look familiar where we are heading. So next, we will group into sentences and create a DataFrame. This time we will have an additional column that has the author's name of the sentence. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "sjrlyo9cxnEQ",
        "outputId": "d5ed6779-bb38-4de9-cdd8-ac497e7da8ca"
      },
      "source": [
        "# Group into sentences\r\n",
        "alice_sents = [[sent, \"Carroll\"] for sent in alice_doc.sents]\r\n",
        "persuasion_sents = [[sent, \"Austen\"] for sent in persuasion_doc.sents]\r\n",
        "\r\n",
        "# Combine the sentences from the two novels into one DataFrame\r\n",
        "sentences = pd.DataFrame(alice_sents + persuasion_sents, columns = [\"text\", \"author\"])\r\n",
        "sentences.head()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>author</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(Alice, was, beginning, to, get, very, tired, ...</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(So, she, was, considering, in, her, own, mind...</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(There, was, nothing, so, VERY, remarkable, in...</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(Oh, dear, !)</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(I, shall, be, late, !, ')</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text   author\n",
              "0  (Alice, was, beginning, to, get, very, tired, ...  Carroll\n",
              "1  (So, she, was, considering, in, her, own, mind...  Carroll\n",
              "2  (There, was, nothing, so, VERY, remarkable, in...  Carroll\n",
              "3                                      (Oh, dear, !)  Carroll\n",
              "4                         (I, shall, be, late, !, ')  Carroll"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7baIazkqyBL1"
      },
      "source": [
        "Not there yet, now we want to remove stop words, punctuation, and lemmatize the tokens.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bNKveyeyLOD"
      },
      "source": [
        "# Get rid of stop words and punctuation,\r\n",
        "# and lemmatize the tokens\r\n",
        "for i, sentence in enumerate(sentences[\"text\"]):\r\n",
        "    sentences.loc[i, \"text\"] = \" \".join(\r\n",
        "        [token.lemma_ for token in sentence if not token.is_punct and not token.is_stop])"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olmFlRLayONM"
      },
      "source": [
        "Now we are ready to try TF-IDF Vectorization. However, let's make it more interesting. If you haven't heard of N-grams. N-grams are sets of N words that appear frequently and consecutively through out the text. A quick example, if we have the following sentence. \r\n",
        "\r\n",
        "I enjoy learning Natural Language Processing.\r\n",
        "\r\n",
        "The corresponding 2-gram would look like this.\r\n",
        "\r\n",
        "    (I enjoy), (enjoy learning), (learning Natural), (Natural Language), (Language Processing).\r\n",
        "\r\n",
        "Previously we looked at the TF-IDF vectorization of a 1-gram, because we looked at a single word. Now, we will at the TF-IDF vectorization of 2-grams. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        },
        "id": "QtCIk9jhzG62",
        "outputId": "57024f98-be23-4d0f-a147-bdaab764f5b1"
      },
      "source": [
        "vectorizer = TfidfVectorizer(\r\n",
        "    max_df=0.5, min_df=2, use_idf=True, norm=u'l2',\r\n",
        "     smooth_idf=True, ngram_range=(2,2)) #The n-gram parameter lets us tell TF-IDF what N-grams to include. \r\n",
        "\r\n",
        "\r\n",
        "# Applying the vectorizer\r\n",
        "X = vectorizer.fit_transform(sentences[\"text\"])\r\n",
        "\r\n",
        "tfidf_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\r\n",
        "sentences = pd.concat([tfidf_df, sentences[[\"text\", \"author\"]]], axis=1)\r\n",
        "\r\n",
        "# Keep in mind that log base 2 of 1 is 0,\r\n",
        "# so a TF-IDF score of 0 indicates that the word was present once in that sentence.\r\n",
        "sentences.head()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>able bear</th>\n",
              "      <th>able persuade</th>\n",
              "      <th>absence home</th>\n",
              "      <th>absolute necessity</th>\n",
              "      <th>absolutely hopeless</th>\n",
              "      <th>accident lyme</th>\n",
              "      <th>accidentally hear</th>\n",
              "      <th>accommodation man</th>\n",
              "      <th>account louisa</th>\n",
              "      <th>account small</th>\n",
              "      <th>acquaint captain</th>\n",
              "      <th>acquaintance ask</th>\n",
              "      <th>acquaintance cease</th>\n",
              "      <th>acquaintance time</th>\n",
              "      <th>acquaintance visit</th>\n",
              "      <th>active service</th>\n",
              "      <th>add certainly</th>\n",
              "      <th>add dormouse</th>\n",
              "      <th>add explanation</th>\n",
              "      <th>add gryphon</th>\n",
              "      <th>add look</th>\n",
              "      <th>admiral baldwin</th>\n",
              "      <th>admiral croft</th>\n",
              "      <th>admiral mrs</th>\n",
              "      <th>admiral think</th>\n",
              "      <th>admire exceedingly</th>\n",
              "      <th>admit doubt</th>\n",
              "      <th>advance twice</th>\n",
              "      <th>advantage see</th>\n",
              "      <th>advice lady</th>\n",
              "      <th>affection confidence</th>\n",
              "      <th>afraid mention</th>\n",
              "      <th>afraid offend</th>\n",
              "      <th>afraid sir</th>\n",
              "      <th>agree captain</th>\n",
              "      <th>agree good</th>\n",
              "      <th>agree have</th>\n",
              "      <th>agree say</th>\n",
              "      <th>agreeable man</th>\n",
              "      <th>agreeable manner</th>\n",
              "      <th>...</th>\n",
              "      <th>word come</th>\n",
              "      <th>word drink</th>\n",
              "      <th>word explain</th>\n",
              "      <th>word listen</th>\n",
              "      <th>word look</th>\n",
              "      <th>word say</th>\n",
              "      <th>word scarcely</th>\n",
              "      <th>world know</th>\n",
              "      <th>world round</th>\n",
              "      <th>worth attend</th>\n",
              "      <th>worth have</th>\n",
              "      <th>write bath</th>\n",
              "      <th>write letter</th>\n",
              "      <th>write slate</th>\n",
              "      <th>writing desk</th>\n",
              "      <th>year ago</th>\n",
              "      <th>year anne</th>\n",
              "      <th>year go</th>\n",
              "      <th>year half</th>\n",
              "      <th>year monkford</th>\n",
              "      <th>year old</th>\n",
              "      <th>year pass</th>\n",
              "      <th>year school</th>\n",
              "      <th>year year</th>\n",
              "      <th>yer honour</th>\n",
              "      <th>yes mr</th>\n",
              "      <th>yes say</th>\n",
              "      <th>yes yes</th>\n",
              "      <th>young child</th>\n",
              "      <th>young fellow</th>\n",
              "      <th>young friend</th>\n",
              "      <th>young lady</th>\n",
              "      <th>young man</th>\n",
              "      <th>young people</th>\n",
              "      <th>young person</th>\n",
              "      <th>young sister</th>\n",
              "      <th>young woman</th>\n",
              "      <th>youth say</th>\n",
              "      <th>text</th>\n",
              "      <th>author</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Alice begin tired sit sister bank have twice p...</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>consider mind hot day feel sleepy stupid pleas...</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>remarkable Alice think way hear Rabbit oh dear</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>oh dear</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>shall late</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  2617 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   able bear  ...   author\n",
              "0        0.0  ...  Carroll\n",
              "1        0.0  ...  Carroll\n",
              "2        0.0  ...  Carroll\n",
              "3        0.0  ...  Carroll\n",
              "4        0.0  ...  Carroll\n",
              "\n",
              "[5 rows x 2617 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQ-FG3SW11bQ"
      },
      "source": [
        "Now our columns are single words, but pairs of words. We see nothing but zeros for the most part but that is okay. We are only looking at the first 5 sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "L-yWeNhB2Frt",
        "outputId": "aff88e25-9113-4317-b956-37cb537207ea"
      },
      "source": [
        "sentences.describe()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>able bear</th>\n",
              "      <th>able persuade</th>\n",
              "      <th>absence home</th>\n",
              "      <th>absolute necessity</th>\n",
              "      <th>absolutely hopeless</th>\n",
              "      <th>accident lyme</th>\n",
              "      <th>accidentally hear</th>\n",
              "      <th>accommodation man</th>\n",
              "      <th>account louisa</th>\n",
              "      <th>account small</th>\n",
              "      <th>acquaint captain</th>\n",
              "      <th>acquaintance ask</th>\n",
              "      <th>acquaintance cease</th>\n",
              "      <th>acquaintance time</th>\n",
              "      <th>acquaintance visit</th>\n",
              "      <th>active service</th>\n",
              "      <th>add certainly</th>\n",
              "      <th>add dormouse</th>\n",
              "      <th>add explanation</th>\n",
              "      <th>add gryphon</th>\n",
              "      <th>add look</th>\n",
              "      <th>admiral baldwin</th>\n",
              "      <th>admiral croft</th>\n",
              "      <th>admiral mrs</th>\n",
              "      <th>admiral think</th>\n",
              "      <th>admire exceedingly</th>\n",
              "      <th>admit doubt</th>\n",
              "      <th>advance twice</th>\n",
              "      <th>advantage see</th>\n",
              "      <th>advice lady</th>\n",
              "      <th>affection confidence</th>\n",
              "      <th>afraid mention</th>\n",
              "      <th>afraid offend</th>\n",
              "      <th>afraid sir</th>\n",
              "      <th>agree captain</th>\n",
              "      <th>agree good</th>\n",
              "      <th>agree have</th>\n",
              "      <th>agree say</th>\n",
              "      <th>agreeable man</th>\n",
              "      <th>agreeable manner</th>\n",
              "      <th>...</th>\n",
              "      <th>wonder happen</th>\n",
              "      <th>wonder shall</th>\n",
              "      <th>word come</th>\n",
              "      <th>word drink</th>\n",
              "      <th>word explain</th>\n",
              "      <th>word listen</th>\n",
              "      <th>word look</th>\n",
              "      <th>word say</th>\n",
              "      <th>word scarcely</th>\n",
              "      <th>world know</th>\n",
              "      <th>world round</th>\n",
              "      <th>worth attend</th>\n",
              "      <th>worth have</th>\n",
              "      <th>write bath</th>\n",
              "      <th>write letter</th>\n",
              "      <th>write slate</th>\n",
              "      <th>writing desk</th>\n",
              "      <th>year ago</th>\n",
              "      <th>year anne</th>\n",
              "      <th>year go</th>\n",
              "      <th>year half</th>\n",
              "      <th>year monkford</th>\n",
              "      <th>year old</th>\n",
              "      <th>year pass</th>\n",
              "      <th>year school</th>\n",
              "      <th>year year</th>\n",
              "      <th>yer honour</th>\n",
              "      <th>yes mr</th>\n",
              "      <th>yes say</th>\n",
              "      <th>yes yes</th>\n",
              "      <th>young child</th>\n",
              "      <th>young fellow</th>\n",
              "      <th>young friend</th>\n",
              "      <th>young lady</th>\n",
              "      <th>young man</th>\n",
              "      <th>young people</th>\n",
              "      <th>young person</th>\n",
              "      <th>young sister</th>\n",
              "      <th>young woman</th>\n",
              "      <th>youth say</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "      <td>5848.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.000180</td>\n",
              "      <td>0.000342</td>\n",
              "      <td>0.000193</td>\n",
              "      <td>0.000376</td>\n",
              "      <td>0.000294</td>\n",
              "      <td>0.000246</td>\n",
              "      <td>0.000129</td>\n",
              "      <td>0.000168</td>\n",
              "      <td>0.000208</td>\n",
              "      <td>0.000189</td>\n",
              "      <td>0.000225</td>\n",
              "      <td>0.000204</td>\n",
              "      <td>0.000258</td>\n",
              "      <td>0.000244</td>\n",
              "      <td>0.000186</td>\n",
              "      <td>0.000235</td>\n",
              "      <td>0.000220</td>\n",
              "      <td>0.000342</td>\n",
              "      <td>0.000342</td>\n",
              "      <td>0.000169</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>0.000532</td>\n",
              "      <td>0.001319</td>\n",
              "      <td>0.000526</td>\n",
              "      <td>0.000262</td>\n",
              "      <td>0.000292</td>\n",
              "      <td>0.000493</td>\n",
              "      <td>0.000265</td>\n",
              "      <td>0.000152</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.000173</td>\n",
              "      <td>0.000199</td>\n",
              "      <td>0.000271</td>\n",
              "      <td>0.000209</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>0.000221</td>\n",
              "      <td>0.000197</td>\n",
              "      <td>0.000276</td>\n",
              "      <td>0.000536</td>\n",
              "      <td>0.000313</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000392</td>\n",
              "      <td>0.000342</td>\n",
              "      <td>0.000239</td>\n",
              "      <td>0.000217</td>\n",
              "      <td>0.000266</td>\n",
              "      <td>0.000264</td>\n",
              "      <td>0.000356</td>\n",
              "      <td>0.000352</td>\n",
              "      <td>0.000292</td>\n",
              "      <td>0.000248</td>\n",
              "      <td>0.000182</td>\n",
              "      <td>0.000124</td>\n",
              "      <td>0.000174</td>\n",
              "      <td>0.000194</td>\n",
              "      <td>0.000187</td>\n",
              "      <td>0.000363</td>\n",
              "      <td>0.000196</td>\n",
              "      <td>0.000507</td>\n",
              "      <td>0.000151</td>\n",
              "      <td>0.000187</td>\n",
              "      <td>0.000294</td>\n",
              "      <td>0.000110</td>\n",
              "      <td>0.000136</td>\n",
              "      <td>0.000296</td>\n",
              "      <td>0.000158</td>\n",
              "      <td>0.000294</td>\n",
              "      <td>0.000542</td>\n",
              "      <td>0.000231</td>\n",
              "      <td>0.000763</td>\n",
              "      <td>0.000872</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>0.000310</td>\n",
              "      <td>0.000353</td>\n",
              "      <td>0.001603</td>\n",
              "      <td>0.002430</td>\n",
              "      <td>0.000988</td>\n",
              "      <td>0.000220</td>\n",
              "      <td>0.000141</td>\n",
              "      <td>0.000828</td>\n",
              "      <td>0.000270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.009833</td>\n",
              "      <td>0.018492</td>\n",
              "      <td>0.010699</td>\n",
              "      <td>0.017218</td>\n",
              "      <td>0.016105</td>\n",
              "      <td>0.014288</td>\n",
              "      <td>0.007002</td>\n",
              "      <td>0.009129</td>\n",
              "      <td>0.009186</td>\n",
              "      <td>0.010269</td>\n",
              "      <td>0.012612</td>\n",
              "      <td>0.011217</td>\n",
              "      <td>0.013970</td>\n",
              "      <td>0.014230</td>\n",
              "      <td>0.010714</td>\n",
              "      <td>0.012724</td>\n",
              "      <td>0.011936</td>\n",
              "      <td>0.018492</td>\n",
              "      <td>0.018492</td>\n",
              "      <td>0.009323</td>\n",
              "      <td>0.011570</td>\n",
              "      <td>0.021163</td>\n",
              "      <td>0.029451</td>\n",
              "      <td>0.017025</td>\n",
              "      <td>0.014829</td>\n",
              "      <td>0.016014</td>\n",
              "      <td>0.021785</td>\n",
              "      <td>0.014937</td>\n",
              "      <td>0.008473</td>\n",
              "      <td>0.009537</td>\n",
              "      <td>0.009546</td>\n",
              "      <td>0.011046</td>\n",
              "      <td>0.015144</td>\n",
              "      <td>0.011325</td>\n",
              "      <td>0.010933</td>\n",
              "      <td>0.011990</td>\n",
              "      <td>0.011387</td>\n",
              "      <td>0.015348</td>\n",
              "      <td>0.021415</td>\n",
              "      <td>0.014054</td>\n",
              "      <td>...</td>\n",
              "      <td>0.017732</td>\n",
              "      <td>0.018492</td>\n",
              "      <td>0.010676</td>\n",
              "      <td>0.013549</td>\n",
              "      <td>0.014945</td>\n",
              "      <td>0.014901</td>\n",
              "      <td>0.015910</td>\n",
              "      <td>0.013659</td>\n",
              "      <td>0.016014</td>\n",
              "      <td>0.011048</td>\n",
              "      <td>0.009979</td>\n",
              "      <td>0.006789</td>\n",
              "      <td>0.009810</td>\n",
              "      <td>0.010859</td>\n",
              "      <td>0.010121</td>\n",
              "      <td>0.016737</td>\n",
              "      <td>0.011068</td>\n",
              "      <td>0.016256</td>\n",
              "      <td>0.008187</td>\n",
              "      <td>0.010527</td>\n",
              "      <td>0.016105</td>\n",
              "      <td>0.005975</td>\n",
              "      <td>0.007446</td>\n",
              "      <td>0.013402</td>\n",
              "      <td>0.008842</td>\n",
              "      <td>0.016105</td>\n",
              "      <td>0.021508</td>\n",
              "      <td>0.013072</td>\n",
              "      <td>0.020919</td>\n",
              "      <td>0.027771</td>\n",
              "      <td>0.011049</td>\n",
              "      <td>0.013819</td>\n",
              "      <td>0.015870</td>\n",
              "      <td>0.034154</td>\n",
              "      <td>0.039126</td>\n",
              "      <td>0.026827</td>\n",
              "      <td>0.011936</td>\n",
              "      <td>0.007809</td>\n",
              "      <td>0.023224</td>\n",
              "      <td>0.015098</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.592882</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.693171</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.396804</td>\n",
              "      <td>0.536117</td>\n",
              "      <td>0.425435</td>\n",
              "      <td>0.610022</td>\n",
              "      <td>0.834300</td>\n",
              "      <td>0.707107</td>\n",
              "      <td>0.790181</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.742853</td>\n",
              "      <td>0.707107</td>\n",
              "      <td>0.707107</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.592882</td>\n",
              "      <td>0.808585</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.793038</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.558952</td>\n",
              "      <td>0.555756</td>\n",
              "      <td>0.605278</td>\n",
              "      <td>0.719065</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.665699</td>\n",
              "      <td>0.663859</td>\n",
              "      <td>0.707107</td>\n",
              "      <td>0.795213</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.755399</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.570672</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.807081</td>\n",
              "      <td>0.585377</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.570672</td>\n",
              "      <td>0.614563</td>\n",
              "      <td>0.418749</td>\n",
              "      <td>0.658861</td>\n",
              "      <td>0.719065</td>\n",
              "      <td>0.558746</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.742853</td>\n",
              "      <td>0.640640</td>\n",
              "      <td>0.480775</td>\n",
              "      <td>0.707107</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.343383</td>\n",
              "      <td>0.455859</td>\n",
              "      <td>0.694943</td>\n",
              "      <td>0.583805</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.883101</td>\n",
              "      <td>0.752760</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.707107</td>\n",
              "      <td>0.716689</td>\n",
              "      <td>0.868720</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.707107</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows  2615 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         able bear  able persuade  ...  young woman    youth say\n",
              "count  5848.000000    5848.000000  ...  5848.000000  5848.000000\n",
              "mean      0.000180       0.000342  ...     0.000828     0.000270\n",
              "std       0.009833       0.018492  ...     0.023224     0.015098\n",
              "min       0.000000       0.000000  ...     0.000000     0.000000\n",
              "25%       0.000000       0.000000  ...     0.000000     0.000000\n",
              "50%       0.000000       0.000000  ...     0.000000     0.000000\n",
              "75%       0.000000       0.000000  ...     0.000000     0.000000\n",
              "max       0.592882       1.000000  ...     1.000000     1.000000\n",
              "\n",
              "[8 rows x 2615 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARBAGOXV2Usl"
      },
      "source": [
        "Now, why would we TF_IDF vectorize a real dataset without building some models? We wouldn't. So let's build some. We will try to see how well we can classify the text based on the TF-IDF vectorization of the 2-grams. We will look at Logistic Regression, Random Forest Classifier, and Gradient Boosting Classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TisPYHoR2I2b",
        "outputId": "0800726f-f471-4def-f23c-3e6bb5daa3c1"
      },
      "source": [
        "# Defining X and Y\r\n",
        "\r\n",
        "Y = sentences['author']\r\n",
        "X = np.array(sentences.drop(['text', 'author'], 1))\r\n",
        "\r\n",
        "# Train, Test, Split\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.4,\r\n",
        "                                                    random_state=123)\r\n",
        "\r\n",
        "# Initializing  and fitting Models\r\n",
        "lr = LogisticRegression()\r\n",
        "rfc = RandomForestClassifier()\r\n",
        "gbc = GradientBoostingClassifier()\r\n",
        "\r\n",
        "lr.fit(X_train, y_train)\r\n",
        "rfc.fit(X_train, y_train)\r\n",
        "gbc.fit(X_train, y_train)\r\n",
        "\r\n",
        "# Results\r\n",
        "print(\"----------------------Logistic Regression Scores----------------------\")\r\n",
        "print('Training set score:', lr.score(X_train, y_train))\r\n",
        "print('\\nTest set score:', lr.score(X_test, y_test))\r\n",
        "\r\n",
        "print(\"----------------------Random Forest Scores----------------------\")\r\n",
        "print('Training set score:', rfc.score(X_train, y_train))\r\n",
        "print('\\nTest set score:', rfc.score(X_test, y_test))\r\n",
        "\r\n",
        "print(\"----------------------Gradient Boosting Scores----------------------\")\r\n",
        "print('Training set score:', gbc.score(X_train, y_train))\r\n",
        "print('\\nTest set score:', gbc.score(X_test, y_test))\r\n",
        "\r\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------Logistic Regression Scores----------------------\n",
            "Training set score: 0.8135689851767389\n",
            "\n",
            "Test set score: 0.7666666666666667\n",
            "----------------------Random Forest Scores----------------------\n",
            "Training set score: 0.8554732041049031\n",
            "\n",
            "Test set score: 0.794017094017094\n",
            "----------------------Gradient Boosting Scores----------------------\n",
            "Training set score: 0.749429874572406\n",
            "\n",
            "Test set score: 0.7525641025641026\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGrwCaCk3MXO"
      },
      "source": [
        "Our models are not the best, but it is just the first model we try. We can see that if we use only 2-grams our Logistic Regression and Random Forest models overfit the data. What if we looked at both 1-grams and 2-grams? Let's find out"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        },
        "id": "ONzfVSX23gnY",
        "outputId": "838a83f5-2d62-40be-aad0-38c050790a4b"
      },
      "source": [
        "vectorizer = TfidfVectorizer(\r\n",
        "    max_df=0.5, min_df=2, use_idf=True, norm=u'l2',\r\n",
        "     smooth_idf=True, ngram_range=(1,2)) #Now we change to (1,2) to include 1-gram!\r\n",
        "\r\n",
        "\r\n",
        "# Applying the vectorizer\r\n",
        "X = vectorizer.fit_transform(sentences[\"text\"])\r\n",
        "\r\n",
        "tfidf_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\r\n",
        "sentences = pd.concat([tfidf_df, sentences[[\"text\", \"author\"]]], axis=1)\r\n",
        "\r\n",
        "# Keep in mind that log base 2 of 1 is 0,\r\n",
        "# so a TF-IDF score of 0 indicates that the word was present once in that sentence.\r\n",
        "sentences.head()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>abide</th>\n",
              "      <th>ability</th>\n",
              "      <th>able</th>\n",
              "      <th>able bear</th>\n",
              "      <th>able persuade</th>\n",
              "      <th>abominate</th>\n",
              "      <th>abroad</th>\n",
              "      <th>absence</th>\n",
              "      <th>absence home</th>\n",
              "      <th>absent</th>\n",
              "      <th>absolute</th>\n",
              "      <th>absolute necessity</th>\n",
              "      <th>absolutely</th>\n",
              "      <th>absolutely hopeless</th>\n",
              "      <th>absurd</th>\n",
              "      <th>abuse</th>\n",
              "      <th>accept</th>\n",
              "      <th>acceptable</th>\n",
              "      <th>acceptance</th>\n",
              "      <th>accession</th>\n",
              "      <th>accident</th>\n",
              "      <th>accident lyme</th>\n",
              "      <th>accidentally</th>\n",
              "      <th>accidentally hear</th>\n",
              "      <th>accommodate</th>\n",
              "      <th>accommodation</th>\n",
              "      <th>accommodation man</th>\n",
              "      <th>accompany</th>\n",
              "      <th>accomplish</th>\n",
              "      <th>accomplishment</th>\n",
              "      <th>accord</th>\n",
              "      <th>accordingly</th>\n",
              "      <th>account</th>\n",
              "      <th>account louisa</th>\n",
              "      <th>account small</th>\n",
              "      <th>accuse</th>\n",
              "      <th>acknowledge</th>\n",
              "      <th>acknowledgement</th>\n",
              "      <th>acquaint</th>\n",
              "      <th>acquaint captain</th>\n",
              "      <th>...</th>\n",
              "      <th>wrong</th>\n",
              "      <th>wrought</th>\n",
              "      <th>yard</th>\n",
              "      <th>yarmouth</th>\n",
              "      <th>yawn</th>\n",
              "      <th>ye</th>\n",
              "      <th>year</th>\n",
              "      <th>year ago</th>\n",
              "      <th>year anne</th>\n",
              "      <th>year go</th>\n",
              "      <th>year half</th>\n",
              "      <th>year monkford</th>\n",
              "      <th>year old</th>\n",
              "      <th>year pass</th>\n",
              "      <th>year school</th>\n",
              "      <th>year year</th>\n",
              "      <th>yer</th>\n",
              "      <th>yer honour</th>\n",
              "      <th>yes</th>\n",
              "      <th>yes mr</th>\n",
              "      <th>yes say</th>\n",
              "      <th>yes yes</th>\n",
              "      <th>yesterday</th>\n",
              "      <th>yield</th>\n",
              "      <th>young</th>\n",
              "      <th>young child</th>\n",
              "      <th>young fellow</th>\n",
              "      <th>young friend</th>\n",
              "      <th>young lady</th>\n",
              "      <th>young man</th>\n",
              "      <th>young people</th>\n",
              "      <th>young person</th>\n",
              "      <th>young sister</th>\n",
              "      <th>young woman</th>\n",
              "      <th>youth</th>\n",
              "      <th>youth say</th>\n",
              "      <th>zeal</th>\n",
              "      <th>zealous</th>\n",
              "      <th>text</th>\n",
              "      <th>author</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Alice begin tired sit sister bank have twice p...</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>consider mind hot day feel sleepy stupid pleas...</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>remarkable Alice think way hear Rabbit oh dear</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>oh dear</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>shall late</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  5482 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   abide  ability  ...                                               text   author\n",
              "0    0.0      0.0  ...  Alice begin tired sit sister bank have twice p...  Carroll\n",
              "1    0.0      0.0  ...  consider mind hot day feel sleepy stupid pleas...  Carroll\n",
              "2    0.0      0.0  ...     remarkable Alice think way hear Rabbit oh dear  Carroll\n",
              "3    0.0      0.0  ...                                            oh dear  Carroll\n",
              "4    0.0      0.0  ...                                         shall late  Carroll\n",
              "\n",
              "[5 rows x 5482 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbiAUkS33l-w"
      },
      "source": [
        "As expected, we now see columns with single and 2-grams. Does this model perform better?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdLJZai_3t6o",
        "outputId": "dffc46d7-0392-4c06-a95a-92d3696403fa"
      },
      "source": [
        "# Defining X and Y\r\n",
        "\r\n",
        "Y = sentences['author']\r\n",
        "X = np.array(sentences.drop(['text', 'author'], 1))\r\n",
        "\r\n",
        "# Train, Test, Split\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.4,\r\n",
        "                                                    random_state=123)\r\n",
        "\r\n",
        "# Initializing  and fitting Models\r\n",
        "lr = LogisticRegression()\r\n",
        "rfc = RandomForestClassifier()\r\n",
        "gbc = GradientBoostingClassifier()\r\n",
        "\r\n",
        "lr.fit(X_train, y_train)\r\n",
        "rfc.fit(X_train, y_train)\r\n",
        "gbc.fit(X_train, y_train)\r\n",
        "\r\n",
        "# Results\r\n",
        "print(\"----------------------Logistic Regression Scores----------------------\")\r\n",
        "print('Training set score:', lr.score(X_train, y_train))\r\n",
        "print('\\nTest set score:', lr.score(X_test, y_test))\r\n",
        "\r\n",
        "print(\"----------------------Random Forest Scores----------------------\")\r\n",
        "print('Training set score:', rfc.score(X_train, y_train))\r\n",
        "print('\\nTest set score:', rfc.score(X_test, y_test))\r\n",
        "\r\n",
        "print(\"----------------------Gradient Boosting Scores----------------------\")\r\n",
        "print('Training set score:', gbc.score(X_train, y_train))\r\n",
        "print('\\nTest set score:', gbc.score(X_test, y_test))\r\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------Logistic Regression Scores----------------------\n",
            "Training set score: 0.9036488027366021\n",
            "\n",
            "Test set score: 0.8555555555555555\n",
            "----------------------Random Forest Scores----------------------\n",
            "Training set score: 0.9694982896237172\n",
            "\n",
            "Test set score: 0.8444444444444444\n",
            "----------------------Gradient Boosting Scores----------------------\n",
            "Training set score: 0.8244013683010262\n",
            "\n",
            "Test set score: 0.8106837606837607\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20R-q4af4QPE"
      },
      "source": [
        "Overall our models all perform better now. However, our Random Forest Model seems to be overfitting the data a lot more. Still, all performed better on the test set. Hopefully these couple of examples have helped you better understand how we can convert text to numerical features that you can use in machine learning models. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BSAL1Va4iL8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}